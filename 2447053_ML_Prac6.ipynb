{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c408ba45",
   "metadata": {},
   "source": [
    "### Name:-Prachi Balaji Upare\n",
    "### Roll no.:-2447053\n",
    "### Batch:-C\n",
    "### Practical No.6:- Build a Tic-Tac-Toe game using reinforcement learning in Python by using following tasks \n",
    "                       a. Setting up the environment\n",
    "                       b. Defining the Tic-Tac-Toe game \n",
    "                       c. Building the reinforcement learning model \n",
    "                       d. Training the model e. Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf1ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Your move (0-8): 4\n",
      "[[ 1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "Your move (0-8): 2\n",
      "[[ 1.  1. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1. -1.]\n",
      " [ 1. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "Your move (0-8): 6\n",
      "[[ 1.  1. -1.]\n",
      " [ 1. -1.  0.]\n",
      " [-1.  0.  0.]]\n",
      "You win!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self): self.board = np.zeros((3, 3)); self.done = False\n",
    "    def reset(self): self.board = np.zeros((3, 3)); self.done = False; return self.board\n",
    "    def check_winner(self):  # Check rows, cols, diagonals for a winner or draw\n",
    "        for i in range(3):\n",
    "            if np.all(self.board[i, :] == 1) or np.all(self.board[:, i] == 1): self.done = True; return 1\n",
    "            if np.all(self.board[i, :] == -1) or np.all(self.board[:, i] == -1): self.done = True; return -1\n",
    "        if np.all(np.diag(self.board) == 1) or np.all(np.diag(np.fliplr(self.board)) == 1): self.done = True; return 1\n",
    "        if np.all(np.diag(self.board) == -1) or np.all(np.diag(np.fliplr(self.board)) == -1): self.done = True; return -1\n",
    "        if not np.any(self.board == 0): self.done = True; return 0\n",
    "    def step(self, action, player): self.board[action // 3, action % 3] = player; return self.board, self.check_winner()\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, epsilon=0.1, alpha=0.5, gamma=0.9): self.q = {}; self.eps = epsilon; self.alpha = alpha; self.gamma = gamma\n",
    "    def get_q(self, state, action): return self.q.get((state, action), 0)\n",
    "    def choose_action(self, state, valid): return np.random.choice(valid) if np.random.rand() < self.eps else valid[np.argmax([self.get_q(state, a) for a in valid])]\n",
    "    def update_q(self, state, action, reward, next_state, valid): best_next = max([self.get_q(next_state, a) for a in valid], default=0); self.q[(state, action)] = self.get_q(state, action) + self.alpha * (reward + self.gamma * best_next - self.get_q(state, action))\n",
    "\n",
    "def train(agent, episodes=1000):\n",
    "    env = TicTacToe()\n",
    "    for _ in range(episodes):\n",
    "        state = env.reset().flatten().tobytes(); player = 1\n",
    "        while not env.done:\n",
    "            valid = [i for i in range(9) if env.board[i // 3, i % 3] == 0]\n",
    "            action = agent.choose_action(state, valid)\n",
    "            next_state, winner = env.step(action, player)\n",
    "            reward = 1 if winner == player else -1 if winner == -player else 0\n",
    "            agent.update_q(state, action, reward, next_state.flatten().tobytes(), valid)\n",
    "            state, player = next_state.flatten().tobytes(), -player\n",
    "\n",
    "def test(agent):\n",
    "    env = TicTacToe(); state = env.reset().flatten().tobytes(); player = 1\n",
    "    while not env.done:\n",
    "        valid = [i for i in range(9) if env.board[i // 3, i % 3] == 0]\n",
    "        action = agent.choose_action(state, valid) if player == 1 else int(input(\"Your move (0-8): \"))\n",
    "        _, winner = env.step(action, player)\n",
    "        print(env.board)\n",
    "        if winner is not None:  # Stop the game when there is a winner or draw\n",
    "            if winner == 1: print(\"Agent wins!\")\n",
    "            elif winner == -1: print(\"You win!\")\n",
    "            else: print(\"It's a draw!\")\n",
    "            break\n",
    "        state, player = env.board.flatten().tobytes(), -player\n",
    "\n",
    "agent = QLearningAgent()\n",
    "train(agent)\n",
    "test(agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
